{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9349a5-9eee-472d-b1a4-2c519cefd1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "\n",
    "def preprocess_mic(value):\n",
    "    \"\"\"Convierte los valores MIC en numéricos, manejando los signos >, <, ≥, ≤.\"\"\"\n",
    "    if pd.isna(value) or value == \"-\":\n",
    "        return np.nan\n",
    "    match = re.match(r'([<>≤≥]?)([0-9\\.]+)', str(value))\n",
    "    if match:\n",
    "        sign, number = match.groups()\n",
    "        number = float(number)\n",
    "        if sign in ('>', '≥'):\n",
    "            return number * 1.5  # Asumimos un incremento del 50%\n",
    "        elif sign in ('<', '≤'):\n",
    "            return number * 0.75  # Asumimos un decremento del 25%\n",
    "        return number\n",
    "    return np.nan\n",
    "\n",
    "def preprocess_mutations(df):\n",
    "    \"\"\"Transforma las mutaciones en variables binarias usando MultiLabelBinarizer.\"\"\"\n",
    "    mutation_data = df.iloc[:, 11:].replace('-', np.nan).fillna('')\n",
    "    mutation_data = mutation_data.applymap(lambda x: set(x.split(',')) if x else set())\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mutation_matrix = pd.DataFrame(mlb.fit_transform(mutation_data), columns=mlb.classes_, index=df.index)\n",
    "    return mutation_matrix\n",
    "\n",
    "# Cargar datos de entrenamiento\n",
    "train_df = pd.read_csv(\"training_data.csv\")\n",
    "\n",
    "# Preprocesar valores MIC\n",
    "for col in ['IMI', 'AZT', 'FEP', 'MER', 'CIP']:\n",
    "    train_df[col] = train_df[col].apply(preprocess_mic)\n",
    "\n",
    "# Transformar etiquetas en valores numéricos\n",
    "label_mapping = {'S': 0, 'I': 1, 'R': 2}\n",
    "for col in ['IMI_label', 'AZT_label', 'FEP_label', 'MER_label', 'CIP_label']:\n",
    "    train_df[col] = train_df[col].map(label_mapping)\n",
    "\n",
    "# Procesar mutaciones\n",
    "mutation_features = preprocess_mutations(train_df)\n",
    "\n",
    "# Preparar datos de entrada\n",
    "X = pd.concat([train_df[['IMI', 'AZT', 'FEP', 'MER', 'CIP']], mutation_features], axis=1)\n",
    "y = train_df[['IMI_label', 'AZT_label', 'FEP_label', 'MER_label', 'CIP_label']]\n",
    "\n",
    "# Dividir en entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "preds = rf.predict(X_val)\n",
    "print(classification_report(y_val, preds))\n",
    "\n",
    "# Cargar y procesar datos de prueba\n",
    "test_df = pd.read_csv(\"test_data.csv\")\n",
    "test_mutations = preprocess_mutations(test_df)\n",
    "X_test = test_mutations.reindex(columns=mutation_features.columns, fill_value=0)\n",
    "\n",
    "# Hacer predicciones sobre datos de prueba\n",
    "test_preds = rf.predict(X_test)\n",
    "pred_labels = pd.DataFrame(test_preds, columns=['IMI_pred', 'AZT_pred', 'FEP_pred', 'MER_pred', 'CIP_pred'])\n",
    "\n",
    "# Guardar resultados\n",
    "output = pd.concat([test_df[['ID']], pred_labels], axis=1)\n",
    "output.to_csv(\"predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
