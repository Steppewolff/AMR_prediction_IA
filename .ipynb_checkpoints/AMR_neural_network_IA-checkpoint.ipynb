{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d21d63-cf9e-4fa9-b0b0-61c94505b880",
   "metadata": {},
   "source": [
    "## 1. Importar módulos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb03ebc-42ea-4b89-9460-7a4e0fd17c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 1. Importar módulos necesarios\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e8bde-811f-448b-b93e-128493b54bdf",
   "metadata": {},
   "source": [
    "## 1.1 Comprobar si los paquetes se han cargado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349020c-2305-4e18-b063-aee52c19e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 1.1 Comprobar si los paquetes se han cargado correctamente\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Eager execution:\", tf.executing_eagerly())\n",
    "\n",
    "# Verificar si Keras funciona\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(20,)),  # Define explícitamente la capa de entrada\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdb6ee3-b2e1-4346-b0b4-91dffc6df51f",
   "metadata": {},
   "source": [
    "## 2. Definir la estructura de los archivos de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97b6c4-88d9-4ab0-bb48-cb0447049254",
   "metadata": {},
   "source": [
    "**training_data.csv**:\n",
    "- Columna 1: strain_id\n",
    "- Columnas 2 a 11: Para cada antibiótico (FEP, MER, IMI, AZT, CIP):\n",
    "      Ejemplo:\n",
    "        FEP_MIC, FEP_eval, MER_MIC, MER_eval, IMI_MIC, IMI_eval, AZT_MIC, AZT_eval, CIP_MIC, CIP_eval\n",
    "  Las evaluaciones tienen 3 categorías: \"sensitive\", \"resistant\" e \"indeterminate\".\n",
    "- Columnas 12 en adelante: Información de mutaciones para 71 genes.\n",
    "   * Si no hay información para un gen: \"-\"\n",
    "   * Si el gen es wild type: NaN\n",
    "   * Si hay mutaciones: cadena con las mutaciones separadas por comas (ej. \"A123T,V456G\")\n",
    "\n",
    "**test_data.csv**:\n",
    "- Columna 1: strain_id\n",
    "- Columnas 2 en adelante: Información de mutaciones para los mismos 71 genes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d9089c-c021-49f8-8cda-2d7755bdda29",
   "metadata": {},
   "source": [
    "## 3. Cargar y preprocesar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e9a67-74ce-489d-8264-23fe71fe030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3. Cargar y preprocesar los datos\n",
    "# Leer el archivo de entrenamiento (1200 cepas)\n",
    "train_df = pd.read_csv('input/training_data.csv', sep=\";\").reset_index(drop=True)\n",
    "print(\"Dimensiones del DataFrame original:\", train_df.shape)\n",
    "\n",
    "# Definir nombres de columnas:\n",
    "# [\"strain_id\", \"FEP_MIC\", \"FEP_eval\", \"MER_MIC\", \"MER_eval\", \"IMI_MIC\", \"IMI_eval\",\n",
    "#  \"AZT_MIC\", \"AZT_eval\", \"CIP_MIC\", \"CIP_eval\", gene1, gene2, ..., gene71]\n",
    "id_col = \"strain_id\"\n",
    "\n",
    "# Evaluaciones clínicas de los antibióticos\n",
    "eval_cols = [\"FEP_eval\", \"MER_eval\", \"IMI_eval\", \"AZT_eval\", \"CIP_eval\"]\n",
    "\n",
    "# Columnas con genes de resistencia\n",
    "gene_cols = train_df.loc[:, \"PA0004\":\"PA5493\"]\n",
    "\n",
    "# Preprocesamiento de los genes: codificación multi-hot por gen\n",
    "# La idea es, para cada gen, construir un vocabulario de mutaciones (observadas en el set de entrenamiento)\n",
    "# y, para cada celda, crear un vector binario indicando la presencia de cada mutación.\n",
    "def build_gene_vocab(df, gene_columns):\n",
    "    vocab = {}\n",
    "    for col in gene_columns:\n",
    "        mutations = set()\n",
    "        for val in df[col]:\n",
    "            if pd.isna(val) or str(val).strip() == \"-\" or str(val).strip() == \"\":\n",
    "                continue\n",
    "            # Dividir las mutaciones por coma\n",
    "            for mut in val.split(\",\"):\n",
    "                mut = mut.strip()\n",
    "                if mut:\n",
    "                    mutations.add(mut)\n",
    "        # Ordenamos el vocabulario para tener un orden fijo\n",
    "        vocab[col] = sorted(list(mutations))\n",
    "    return vocab\n",
    "\n",
    "gene_vocab = build_gene_vocab(train_df, gene_cols)\n",
    "\n",
    "print('Vocabulario de mutaciones: gene_vocab')\n",
    "print(gene_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a1c0f5-3e30-4f4a-8387-0b3e3be96891",
   "metadata": {},
   "source": [
    "## 3.1 Codificar matrices para el set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc27c21-df81-4cb3-9de2-588a283ee5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para codificar una fila: para cada gen, si la celda está vacía se retorna un vector de ceros,\n",
    "# si tiene mutaciones, se asigna 1 en las posiciones correspondientes al vocabulario.\n",
    "def encode_gene_row(row, gene_columns, vocab):\n",
    "    features = []\n",
    "    for col in gene_columns:\n",
    "        gene_voc = vocab[col]\n",
    "        vec = np.zeros(len(gene_voc), dtype=int)\n",
    "        cell = row[col]\n",
    "        if pd.isna(cell) or str(cell).strip() == \"-\" or str(cell).strip() == \"\":\n",
    "            # Wild type: vector de ceros\n",
    "            pass\n",
    "        else:\n",
    "            mutations = [m.strip() for m in cell.split(\",\") if m.strip() != \"\"]\n",
    "            for mut in mutations:\n",
    "                if mut in gene_voc:\n",
    "                    idx = gene_voc.index(mut)\n",
    "                    vec[idx] = 1\n",
    "        # Agregar el vector para este gen a la lista de características\n",
    "        features.extend(vec.tolist())\n",
    "    return features\n",
    "\n",
    "print(\"Número de índices únicos en train_df:\", train_df.index.nunique())\n",
    "\n",
    "# # Aplicar la codificación a cada fila para los genes en el set de entrenamiento\n",
    "X_train_list = [encode_gene_row(row, gene_cols, gene_vocab) for _, row in train_df.iterrows()]\n",
    "print(\"Número de muestras generadas:\", len(X_train_list))\n",
    "X_train_genes = np.array(X_train_list)\n",
    "print(\"Dimensiones de X_train_genes:\", X_train_genes.shape)\n",
    "\n",
    "# Preparar las etiquetas para caracterizar clínicamente los valores MIC:\n",
    "# Cada evaluación es una cadena con una de 3 categorías: \"sensitive\", \"resistant\" o \"indeterminate\".\n",
    "y_antibiotics = {}\n",
    "antibiotic_encoders = {}\n",
    "\n",
    "for col in eval_cols:\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(train_df[col].astype(str).str.lower())\n",
    "    antibiotic_encoders[col] = le\n",
    "    # Convertimos a formato one-hot (aunque en clasificación binaria se puede usar una sola neurona con sigmoide)\n",
    "    # One-hot encoding para 3 clases *********************************REVISAR**********************************¿como se codifican las 3 clases?\n",
    "    y_antibiotics[col] = to_categorical(y_enc)\n",
    "\n",
    "\n",
    "# Creamos el diccionario de salidas para el modelo multi-salida (5 salidas, una por antibiótico)\n",
    "y_train = {\n",
    "    'FEP': y_antibiotics[\"FEP_eval\"],\n",
    "    'MER': y_antibiotics[\"MER_eval\"],\n",
    "    'IMI': y_antibiotics[\"IMI_eval\"],\n",
    "    'AZT': y_antibiotics[\"AZT_eval\"],\n",
    "    'CIP': y_antibiotics[\"CIP_eval\"]\n",
    "}\n",
    "\n",
    "\n",
    "# La entrada del modelo será únicamente la información codificada de los genes.\n",
    "X_train_input = X_train_genes\n",
    "print(\"Dimensiones de X_train_input:\", X_train_input.shape)\n",
    "\n",
    "# Cargar datos de test (200 cepas)\n",
    "test_df = pd.read_csv('input/test_data.csv',sep=\";\")\n",
    "# Se asume que test_data.csv tiene: \"strain_id\" y luego las 71 columnas de genes con los mismos nombres.\n",
    "test_gene_cols = test_df.columns[1:]\n",
    "X_test_genes = test_df.apply(lambda row: encode_gene_row(row, test_gene_cols, gene_vocab), axis=1)\n",
    "X_test_input = np.array(X_test_genes.tolist())\n",
    "print(\"Dimensiones de X_test_input:\", X_test_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da70fdb1-17b4-49d3-9886-47020ce4518b",
   "metadata": {},
   "source": [
    "## 4. Definir una capa Cross para capturar interacciones entre mutaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f15e6e-2f02-43d6-b722-f89a000a60c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 4. Definir una capa Cross para capturar interacciones entre mutaciones\n",
    "class CrossLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers=1, **kwargs):\n",
    "        super(CrossLayer, self).__init__(**kwargs)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.cross_weights = []\n",
    "        self.cross_biases = []\n",
    "        d = int(input_shape[-1])\n",
    "        for i in range(self.num_layers):\n",
    "            self.cross_weights.append(\n",
    "                self.add_weight(name=f'cross_w_{i}',\n",
    "                                shape=(d, 1),\n",
    "                                initializer='glorot_uniform',\n",
    "                                trainable=True)\n",
    "            )\n",
    "            self.cross_biases.append(\n",
    "                self.add_weight(name=f'cross_b_{i}',\n",
    "                                shape=(d,),\n",
    "                                initializer='zeros',\n",
    "                                trainable=True)\n",
    "            )\n",
    "        super(CrossLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x0 = inputs\n",
    "        x = inputs\n",
    "        for i in range(self.num_layers):\n",
    "            dot = tf.matmul(x, self.cross_weights[i])  # (batch_size, 1)\n",
    "            x = x0 * dot + self.cross_biases[i] + x\n",
    "        return x\n",
    "\n",
    "    print(\"Matrices CrossLayer creadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ed3651-6f2e-4cc9-9914-6938f28128b6",
   "metadata": {},
   "source": [
    "## 5. Definir el modelo de redes neuronales multi-salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a6b1d-1351-4c3b-9dc7-c1d8f141184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 5. Definir el modelo de redes neuronales multi-salida\n",
    "#\n",
    "# Se construirán 5 salidas, una para cada antibiótico, cada una con 3 neuronas (softmax).\n",
    "input_layer = Input(shape=(X_train_input.shape[1],), name='input')\n",
    "x = Dense(256, activation='relu')(input_layer)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "# Capa Cross para modelar interacciones entre las mutaciones\n",
    "x = CrossLayer(num_layers=1)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "print(\"Salidas creadas\")\n",
    "\n",
    "# Salidas para cada antibiótico: FEP, MER, IMI, AZT, CIP\n",
    "out_FEP = Dense(3, activation='softmax', name='FEP')(x)\n",
    "out_MER = Dense(3, activation='softmax', name='MER')(x)\n",
    "out_IMI = Dense(3, activation='softmax', name='IMI')(x)\n",
    "out_AZT = Dense(3, activation='softmax', name='AZT')(x)\n",
    "out_CIP = Dense(3, activation='softmax', name='CIP')(x)\n",
    "\n",
    "print(\"Ejecutando modelo\")\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=[out_FEP, out_MER, out_IMI, out_AZT, out_CIP])\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'FEP': 'categorical_crossentropy',\n",
    "                    'MER': 'categorical_crossentropy',\n",
    "                    'IMI': 'categorical_crossentropy',\n",
    "                    'AZT': 'categorical_crossentropy',\n",
    "                    'CIP': 'categorical_crossentropy'},\n",
    "              metrics={'FEP': 'accuracy',\n",
    "                       'MER': 'accuracy',\n",
    "                       'IMI': 'accuracy',\n",
    "                       'AZT': 'accuracy',\n",
    "                       'CIP': 'accuracy'})\n",
    "\n",
    "model.summary()\n",
    "print(\"Calculados parametros para modelo\")\n",
    "print(pd.Timestamp.now())\n",
    "\n",
    "for col in eval_cols:\n",
    "    unique_vals = train_df[col].astype(str).str.lower().unique()\n",
    "    print(f\"{col} -> {unique_vals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f590b247-87c9-4b16-aed4-9bb34cc0f845",
   "metadata": {},
   "source": [
    "## 6. Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2628a3-6d88-4fca-be42-c3ffd8b7d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 6. Entrenar el modelo\n",
    "print(\"Dimensiones del DataFrame original:\", train_df.shape)\n",
    "print(\"Dimensiones de X_train_input:\", X_train_input.shape)\n",
    "for key in y_train:\n",
    "    print(f\"Dimensiones de y_train[{key}]:\", y_train[key].shape)\n",
    "\n",
    "history = model.fit(X_train_input, y_train,\n",
    "                    epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "print(\"Modelo entrenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e1c8b-7403-4ab1-9ef6-2c2f9633e4a5",
   "metadata": {},
   "source": [
    "## 7. Predicción en el set de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241b7b0-47e0-48a7-83d3-7bc348f78771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 7. Predicción en el set de test\n",
    "#\n",
    "# En el set de test se dispone únicamente de la información de mutaciones (no de MIC).\n",
    "predictions = model.predict(X_test_input)\n",
    "\n",
    "# Para cada antibiótico, se toma la clase con mayor probabilidad.\n",
    "pred_FEP = np.argmax(predictions[0], axis=1)\n",
    "pred_MER = np.argmax(predictions[1], axis=1)\n",
    "pred_IMI = np.argmax(predictions[2], axis=1)\n",
    "pred_AZT = np.argmax(predictions[3], axis=1)\n",
    "pred_CIP = np.argmax(predictions[4], axis=1)\n",
    "\n",
    "# Convertir las predicciones a etiquetas legibles usando los encoders definidos para cada evaluación.\n",
    "pred_FEP_labels = antibiotic_encoders[\"FEP_eval\"].inverse_transform(pred_FEP)\n",
    "pred_MER_labels = antibiotic_encoders[\"MER_eval\"].inverse_transform(pred_MER)\n",
    "pred_IMI_labels = antibiotic_encoders[\"IMI_eval\"].inverse_transform(pred_IMI)\n",
    "pred_AZT_labels = antibiotic_encoders[\"AZT_eval\"].inverse_transform(pred_AZT)\n",
    "pred_CIP_labels = antibiotic_encoders[\"CIP_eval\"].inverse_transform(pred_CIP)\n",
    "\n",
    "results_df = pd.read_csv('input/test_solved.csv', sep=\";\")\n",
    "\n",
    "success = {\"FEP\":0, \"MER\":0, \"IMI\":0, \"AZT\":0, \"CIP\":0}\n",
    "for index, result in results_df[\"FEP_eval\"].items():\n",
    "    if pred_FEP_labels[index] == result.lower():\n",
    "        success[\"FEP\"] = success[\"FEP\"] + 1 \n",
    "\n",
    "for index, result in results_df[\"MER_eval\"].items():\n",
    "    if pred_FEP_labels[index] == result.lower():\n",
    "        success[\"MER\"] = success[\"MER\"] + 1 \n",
    "\n",
    "for index, result in results_df[\"IMI_eval\"].items():\n",
    "    if pred_FEP_labels[index] == result.lower():\n",
    "        success[\"IMI\"] = success[\"IMI\"] + 1 \n",
    "\n",
    "for index, result in results_df[\"AZT_eval\"].items():\n",
    "    if pred_FEP_labels[index] == result.lower():\n",
    "        success[\"AZT\"] = success[\"AZT\"] + 1 \n",
    "\n",
    "for index, result in results_df[\"CIP_eval\"].items():\n",
    "    if pred_FEP_labels[index] == result.lower():\n",
    "        success[\"CIP\"] = success[\"CIP\"] + 1 \n",
    "        \n",
    "print(\"Tasa de predicción correcta:\")\n",
    "for ab, value in success.items():\n",
    "    print(ab, \" : \", value/44)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
