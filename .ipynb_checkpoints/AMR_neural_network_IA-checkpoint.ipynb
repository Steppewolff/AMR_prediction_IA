{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d21d63-cf9e-4fa9-b0b0-61c94505b880",
   "metadata": {},
   "source": [
    "## 1. Importar módulos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb03ebc-42ea-4b89-9460-7a4e0fd17c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 11:48:21.096841: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-03 11:48:21.099252: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-03 11:48:21.106773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738579701.120029   21500 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738579701.123909   21500 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-03 11:48:21.136942: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 1. Importar módulos necesarios\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e8bde-811f-448b-b93e-128493b54bdf",
   "metadata": {},
   "source": [
    "## 1.1 Comprobar si los paquetes se han cargado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349020c-2305-4e18-b063-aee52c19e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 1.1 Comprobar si los paquetes se han cargado correctamente\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Eager execution:\", tf.executing_eagerly())\n",
    "\n",
    "# Verificar si Keras funciona\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(20,)),  # Define explícitamente la capa de entrada\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e6baa-b97a-421e-b9ff-d27973283d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 2. Definir la estructura de los archivos de entrada\n",
    "#\n",
    "# **Archivo de Entrenamiento (\"training_data.csv\")**:\n",
    "# - Columnas 1 a 160: Genes de resistencia.\n",
    "#   - Valor: \"\" (vacío) si la cepa es wild type para ese gen.\n",
    "#   - Valor: Cadena de mutaciones separadas por comas, e.g., \"A123T,V456G\", si hay mutaciones.\n",
    "# - Columnas 161 a 163: \"IMI_MIC\", \"AZT_MIC\", \"FEP_MIC\" (valores numéricos, pero no se usan directamente en el modelo).\n",
    "# - Columnas 164 a 166: \"IMI_eval\", \"AZT_eval\", \"FEP_eval\" (evaluación clínica: \"sensitive\" o \"resistant\").\n",
    "# - Columna 167: \"danger_profile\" (por ejemplo, \"sensitive\", \"MDR\", \"XDR\").\n",
    "#\n",
    "# **Archivo de Test (\"test_data.csv\")**:\n",
    "# - Columnas 1 a 160: Genes de resistencia (mismo formato).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc27c21-df81-4cb3-9de2-588a283ee5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 3. Cargar y preprocesar los datos\n",
    "# Leer el archivo de entrenamiento (1200 cepas)\n",
    "train_df = pd.read_csv('training_data.csv')\n",
    "\n",
    "# Suponemos que las primeras 160 columnas son genes de resistencia\n",
    "gene_cols = train_df.columns[:160]\n",
    "\n",
    "# --- Preprocesamiento de los genes: codificación multi-hot por gen ---\n",
    "# La idea es, para cada gen, construir un vocabulario de mutaciones (observadas en el set de entrenamiento)\n",
    "# y, para cada celda, crear un vector binario indicando la presencia de cada mutación.\n",
    "def build_gene_vocab(df, gene_columns):\n",
    "    vocab = {}\n",
    "    for col in gene_columns:\n",
    "        mutations = set()\n",
    "        for val in df[col]:\n",
    "            if pd.isna(val) or val.strip() == \"\":\n",
    "                continue\n",
    "            # Dividir las mutaciones por coma\n",
    "            for mut in val.split(\",\"):\n",
    "                mut = mut.strip()\n",
    "                if mut:\n",
    "                    mutations.add(mut)\n",
    "        # Ordenamos el vocabulario para tener un orden fijo\n",
    "        vocab[col] = sorted(list(mutations))\n",
    "    return vocab\n",
    "\n",
    "gene_vocab = build_gene_vocab(train_df, gene_cols)\n",
    "\n",
    "# Función para codificar una fila: para cada gen, si la celda está vacía se retorna un vector de ceros,\n",
    "# si tiene mutaciones, se asigna 1 en las posiciones correspondientes al vocabulario.\n",
    "def encode_gene_row(row, gene_columns, vocab):\n",
    "    features = []\n",
    "    for col in gene_columns:\n",
    "        gene_voc = vocab[col]\n",
    "        vec = np.zeros(len(gene_voc), dtype=int)\n",
    "        cell = row[col]\n",
    "        if pd.isna(cell) or cell.strip() == \"\":\n",
    "            # Wild type: vector de ceros\n",
    "            pass\n",
    "        else:\n",
    "            mutations = [m.strip() for m in cell.split(\",\") if m.strip() != \"\"]\n",
    "            for mut in mutations:\n",
    "                if mut in gene_voc:\n",
    "                    idx = gene_voc.index(mut)\n",
    "                    vec[idx] = 1\n",
    "        # Agregar el vector para este gen a la lista de características\n",
    "        features.extend(vec.tolist())\n",
    "    return features\n",
    "\n",
    "# Aplicar la codificación a cada fila para los genes en el set de entrenamiento\n",
    "X_train = train_df.apply(lambda row: encode_gene_row(row, gene_cols, gene_vocab), axis=1)\n",
    "X_train = np.array(X_train.tolist())\n",
    "\n",
    "# Preparar las etiquetas:\n",
    "# Usaremos las evaluaciones clínicas de MIC para 3 antibióticos (IMI, AZT, FEP) y el perfil de peligrosidad.\n",
    "# Suponemos que las columnas de evaluación están etiquetadas como \"IMI_eval\", \"AZT_eval\", \"FEP_eval\"\n",
    "antibiotic_cols = ['IMI_eval', 'AZT_eval', 'FEP_eval']\n",
    "y_antibiotics = train_df[antibiotic_cols]\n",
    "\n",
    "# Para cada antibiótico, codificamos las etiquetas (\"sensitive\" o \"resistant\") en formato binario.\n",
    "antibiotic_encoders = {}\n",
    "y_antibiotics_encoded = {}\n",
    "for col in antibiotic_cols:\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y_antibiotics[col].astype(str))\n",
    "    antibiotic_encoders[col] = le\n",
    "    # Convertimos a formato one-hot (aunque en clasificación binaria se puede usar una sola neurona con sigmoide)\n",
    "    y_antibiotics_encoded[col] = to_categorical(y_enc)\n",
    "\n",
    "# Para el perfil de peligrosidad (por ejemplo: \"sensitive\", \"MDR\", \"XDR\")\n",
    "le_profile = LabelEncoder()\n",
    "y_profile = le_profile.fit_transform(train_df['danger_profile'].astype(str))\n",
    "y_profile_cat = to_categorical(y_profile)\n",
    "\n",
    "# Para este ejemplo, definiremos las salidas de la siguiente forma:\n",
    "# - Para cada antibiótico: salida binaria (usaremos 1 neurona con sigmoide)  \n",
    "#   Por ello, en lugar de one-hot, convertiremos las etiquetas a 0/1.\n",
    "y_antibiotics_binary = {}\n",
    "for col in antibiotic_cols:\n",
    "    # Supongamos que \"resistant\" es 1 y \"sensitive\" es 0\n",
    "    y_binary = (y_antibiotics[col].astype(str).str.lower() == \"resistant\").astype(int)\n",
    "    y_antibiotics_binary[col] = y_binary.values.reshape(-1, 1)\n",
    "\n",
    "# Consolidamos las salidas en un diccionario para el modelo multi-salida\n",
    "y_train = {\n",
    "    'IMI': y_antibiotics_binary['IMI_eval'],\n",
    "    'AZT': y_antibiotics_binary['AZT_eval'],\n",
    "    'FEP': y_antibiotics_binary['FEP_eval'],\n",
    "    'profile': y_profile_cat\n",
    "}\n",
    "\n",
    "# Como nuestros datos de genes ya están en formato binario (multi-hot), la estandarización puede no ser necesaria.\n",
    "X_train_input = X_train  # Forma: (1200, total_features) donde total_features = sum(len(vocab[gene]) for each gene)\n",
    "\n",
    "# Cargar los datos de test (200 cepas), que solo tienen las 160 columnas de genes.\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "# Asegurarse de que los test tengan las mismas columnas y procesarlos de la misma forma\n",
    "for col in gene_cols:\n",
    "    test_df[col] = test_df[col].astype(str)\n",
    "X_test = test_df.apply(lambda row: encode_gene_row(row, gene_cols, gene_vocab), axis=1)\n",
    "X_test_input = np.array(X_test.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a6b1d-1351-4c3b-9dc7-c1d8f141184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 4. Definir el modelo de redes neuronales multi-salida\n",
    "#\n",
    "# Utilizaremos el API funcional de Keras para construir un modelo que tenga dos tipos de salidas:\n",
    "# - Tres salidas binarias para la evaluación de IMI, AZT y FEP.\n",
    "# - Una salida multiclase para el perfil de peligrosidad (3 clases).\n",
    "input_layer = Input(shape=(X_train_input.shape[1],), name='input')\n",
    "x = Dense(256, activation='relu')(input_layer)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# Salidas para antibióticos (una neurona cada uno con activación sigmoide)\n",
    "out_IMI = Dense(1, activation='sigmoid', name='IMI')(x)\n",
    "out_AZT = Dense(1, activation='sigmoid', name='AZT')(x)\n",
    "out_FEP = Dense(1, activation='sigmoid', name='FEP')(x)\n",
    "\n",
    "# Salida para perfil de peligrosidad (3 clases, activación softmax)\n",
    "out_profile = Dense(3, activation='softmax', name='profile')(x)\n",
    "\n",
    "# Definir el modelo con entradas y salidas\n",
    "model = Model(inputs=input_layer, outputs=[out_IMI, out_AZT, out_FEP, out_profile])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'IMI': 'binary_crossentropy',\n",
    "                    'AZT': 'binary_crossentropy',\n",
    "                    'FEP': 'binary_crossentropy',\n",
    "                    'profile': 'categorical_crossentropy'},\n",
    "              metrics={'IMI': 'accuracy',\n",
    "                       'AZT': 'accuracy',\n",
    "                       'FEP': 'accuracy',\n",
    "                       'profile': 'accuracy'})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2628a3-6d88-4fca-be42-c3ffd8b7d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 5. Entrenar el modelo\n",
    "history = model.fit(X_train_input, y_train,\n",
    "                    epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241b7b0-47e0-48a7-83d3-7bc348f78771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 6. Evaluar el modelo en el set de test\n",
    "#\n",
    "# Para el set de test, se usa únicamente la información de las mutaciones para predecir:\n",
    "# - La probabilidad de resistencia para cada antibiótico (se puede usar un umbral, p.ej. 0.5)\n",
    "# - El perfil de peligrosidad (la clase con mayor probabilidad)\n",
    "predictions = model.predict(X_test_input)\n",
    "\n",
    "# Para las salidas binarias, aplicar umbral 0.5\n",
    "pred_IMI = (predictions[0] > 0.5).astype(int)\n",
    "pred_AZT = (predictions[1] > 0.5).astype(int)\n",
    "pred_FEP = (predictions[2] > 0.5).astype(int)\n",
    "# Para el perfil, se toma la clase de mayor probabilidad\n",
    "pred_profile = np.argmax(predictions[3], axis=1)\n",
    "pred_profile_labels = le_profile.inverse_transform(pred_profile)\n",
    "\n",
    "# Mostrar algunas predicciones (ejemplo: perfil de peligrosidad)\n",
    "print(\"Predicción del perfil de peligrosidad para las primeras 5 cepas del set de test:\")\n",
    "print(pred_profile_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
